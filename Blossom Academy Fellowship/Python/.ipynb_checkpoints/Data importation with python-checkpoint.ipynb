{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYS-qhfIHHoV"
   },
   "source": [
    "## In this lesson, you will learn to:\n",
    "\n",
    "1. import flat files (csv,text, etc)\n",
    "\n",
    "2. import data for the web\n",
    "\n",
    "3. connect and access data form relational data base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxTAjgxYHHod"
   },
   "source": [
    "### importing flat files with numpy\n",
    "\n",
    "Flat files are basically text files that contain records usually in two dimentions(rows and columns) with no structured relationships.\n",
    "\n",
    "Data in flat files are separeted by delimeters.(eg:comma or tab)\n",
    "\n",
    "A common example of flat files includes **csv files** and **txt files**\n",
    " \n",
    "To load text files with core python, check the python programming tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1654822659131,
     "user": {
      "displayName": "Digital Africa Data Analytics[Nigeria]",
      "userId": "14488350832621730746"
     },
     "user_tz": -60
    },
    "id": "Zc9AZwVXHHof"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O-kpv5hHHoh"
   },
   "source": [
    "##### Reading flat files with numpy.\n",
    "Common numpy functions for loading data includes np.loadtxt and np.genfromtxt()\n",
    "\n",
    "Whilst np.loadtxt is for loading only uniform data types, np.genfromtxt can be used for mixed data types when dtype\n",
    "argument is set to None.\n",
    "\n",
    "You can also use **np.recfromcsv()** specifically for csv files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG99OnDtHHoi"
   },
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DSGJDiHeHHoj"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "mnist.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6da52ab16aac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#np.loadtxt()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmnist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    529\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: mnist.csv not found."
     ]
    }
   ],
   "source": [
    "#np.loadtxt()\n",
    "\n",
    "mnist=np.loadtxt('mnist.csv',delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgzWC1UEHHok",
    "outputId": "7ff1936e-bb5d-410b-ecd6-76c6ac862ca7"
   },
   "outputs": [],
   "source": [
    "# Fisrt 10\n",
    "\n",
    "mnist[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqRYSM9UHHom"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PS1TtiyoHHon",
    "outputId": "1250c936-132a-4731-d06c-6c96849f6ba8"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxDuzk3pHHoo",
    "outputId": "fab6c07a-c96c-4fa6-ef5b-016c07a5ff72"
   },
   "outputs": [],
   "source": [
    "#genfromtxt\n",
    "\n",
    "data = np.genfromtxt('titanic_sub.csv', delimiter=',', names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPSEQXO2HHop",
    "outputId": "dfe37f59-5109-49d8-c42d-acb7e8064e32"
   },
   "outputs": [],
   "source": [
    "# Fisrt 10\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPMAqjmxHHoq"
   },
   "outputs": [],
   "source": [
    "# recfromcsv()\n",
    "\n",
    "d = np.recfromcsv('titanic_sub.csv',delimiter=',',names = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOh4XekCHHor",
    "outputId": "323fb1f2-fab7-4669-c4e0-6655c518ede9"
   },
   "outputs": [],
   "source": [
    "d[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2xAkoq7HHos"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1af2-2NxHHos"
   },
   "source": [
    "### Importing flat files with pandas\n",
    "\n",
    "To import a csv file with pandas, use the format below:\n",
    "\n",
    "df = pd.read_csv(file path,sep,delimiter,header, names,index_col,usecols,parse_dates,....)\n",
    "\n",
    "Use **.to_csv** : to Write (save)DataFrame to a comma-separated values (csv) file.\n",
    "\n",
    "**NB: For easy data importation, make sure your data is in your workng directory.**\n",
    "\n",
    "Use pwd to check for current working directory(file path) and ls command to list all the files in your working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njWrK140HHot",
    "outputId": "d45a91f3-8a72-4366-ef82-a83bbb4efd54"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOTOvcTOHHot",
    "outputId": "3f4b49f6-91b9-4777-e646-f7b1654db20a"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAi-1n__HHou"
   },
   "outputs": [],
   "source": [
    "#reading the titanic dataset\n",
    "titanic = pd.read_csv('titanic_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucGhUk-RHHov",
    "outputId": "8192f2fd-8aa4-4290-f2e4-03e43d938b83"
   },
   "outputs": [],
   "source": [
    "# First 5 rows\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hw6Um1DKHHov",
    "outputId": "8c4529ff-f9fd-4c08-8287-85d49bfb0bb7"
   },
   "outputs": [],
   "source": [
    "# Last five rows\n",
    "titanic.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Q0vu4mlHHox"
   },
   "source": [
    "#### Reading data and parsing strings as dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jCa-U9pHHoy",
    "outputId": "c42e8b3e-44bc-4a37-e7b0-fa903e430a9c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather_data_na.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnHCy9PNHHoz",
    "outputId": "ace9611f-8c84-4d62-9fd8-772c58a65863"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqxAmWmzHHoz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather_data_na.csv\",parse_dates=[\"day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vsWAQUwHHo0",
    "outputId": "48b5220d-7cfc-4680-c4af-ba0b22ffdba9"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU9Ya1k0HHo0"
   },
   "source": [
    "#### Saving a DataFrame to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXFoH4HhHHo1"
   },
   "outputs": [],
   "source": [
    "df.to_csv('new_weather_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89h-BUDhHHo1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcALMNbjHHo1"
   },
   "source": [
    "### Importing excel files with pandas\n",
    "\n",
    "To read data from excel sheets, use the format below:\n",
    "\n",
    "df = pd.read_excel(file path,sheet_name, header,name,index_col,usecols,skiprows,nrows.....)\n",
    "\n",
    "Use **.to_excel()** to write DataFrame to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcvLBhvsHHo2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N535dg9oHHo2"
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"new.xlsx\",\"Sheet1\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PR0lgnPZHHo2",
    "outputId": "66e20698-1a99-442f-9ef8-e5b6057538ed"
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_excel(\"new.xlsx\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8L3FcukHHo3"
   },
   "outputs": [],
   "source": [
    "#### saving multiple DataFrames to a single work book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQuIU-RJHHo3"
   },
   "outputs": [],
   "source": [
    "df_stocks = pd.DataFrame({'tickets':['GOODL','WIT','NSFT'],\n",
    "                         'price':[845,65,64],\n",
    "                         'pe':[30.37,14.26,30.97],\n",
    "                         'eps':[27.82,4.61,2.12]})\n",
    "\n",
    "df_weather = pd.DataFrame({'day':['1/1/2017','1/2/2017','1/3/2017'],\n",
    "                          'temperature':[32,35,28],\n",
    "                          'event':['Rain','Sunny','Snow']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HUbL_FdHHo4"
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('stocks_weather.xlsx') as book:\n",
    "    df_stocks.to_excel(book,sheet_name='stocks',index=False)\n",
    "    df_weather.to_excel(book,sheet_name = 'weather',index=False)\n",
    "    index=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBazOSXhHHo4",
    "outputId": "32c0d2ca-aea8-482e-ae58-15aeb6dd3567"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"stocks_weather.xlsx\",\"weather\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xILnuK4JHHo4",
    "outputId": "4fe5e85d-573d-41e1-cb12-84a5edb4e455"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(\"stocks_weather.xlsx\",\"stocks\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMRhE-pFHHo5"
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_excel(\"stocks_weather.xlsx\")# if the sheet name is not specified, the first sheet is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2iIu_nfHHo5",
    "outputId": "93a84da5-85d2-42f0-9520-2926f942b18e"
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RTeKKLMHHo5"
   },
   "source": [
    "**Reading an excel book**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBwO5f41HHo6"
   },
   "outputs": [],
   "source": [
    "data = pd.ExcelFile(\"stocks_weather.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amZgvdvSHHo6",
    "outputId": "d32f1bed-67ea-4d50-b698-6f233919e05e"
   },
   "outputs": [],
   "source": [
    "#getting the sheet names\n",
    "data.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrRzSANsHHo6",
    "outputId": "e798d457-a285-4a98-a1b8-46348e469266"
   },
   "outputs": [],
   "source": [
    "# Each sheet can be extracted using the sheet_name or the sheet index and the parse method.\n",
    "stocks = data.parse('stocks')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ge8f_DAqHHo7",
    "outputId": "ef630d92-211f-4c23-bb34-95ac78ad9121"
   },
   "outputs": [],
   "source": [
    "data.parse(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGfXHszdHHo7",
    "outputId": "c0d6e251-72a4-4e89-c723-76e2e0ec51da"
   },
   "outputs": [],
   "source": [
    "weather = data.parse('weather')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r09Hkeb0HHo7",
    "outputId": "30d5adf2-b6a1-4a1e-c009-d1af4e3092f0"
   },
   "outputs": [],
   "source": [
    "data.parse(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8v3rVZ1HHo8"
   },
   "source": [
    "NB: There are other arguments you can specify in the parse method like usecol,skiprows,names ....etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yr8ovBdTHHo8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ej9n8FG7HHo8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buywFMLRHHo8"
   },
   "source": [
    "## Importing pickel files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yySXec-6HHo9"
   },
   "outputs": [],
   "source": [
    "# # Import pickle package\n",
    "# import pickle\n",
    "\n",
    "# # Open pickle file and load data: d\n",
    "# with open('data.pkl', 'rb') as file:\n",
    "#     d = pickle.load(file)\n",
    "\n",
    "# # Print d\n",
    "# print(d)\n",
    "\n",
    "# # Print datatype of d\n",
    "# print(type(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBR4LtuiHHo9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSDTBVMtHHo9"
   },
   "source": [
    "### Importing SAS (Statistical Analysis System) and Stata (Statistics + Data) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D30ab6XDHHo9",
    "outputId": "122c7204-b8ee-4148-f401-49e1e15beaab"
   },
   "outputs": [],
   "source": [
    "\n",
    "# SAS files\n",
    "\n",
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('sales.sas7bdat') as file:\n",
    "    df_sas =file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df_sas.head())\n",
    "\n",
    "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
    "pd.DataFrame.hist(df_sas[['P']])\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd3X3d50HHo-"
   },
   "source": [
    "# Stata Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kV4xPKfZHHo-"
   },
   "outputs": [],
   "source": [
    "# Stata Files\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df=pd.read_stata('disarea.dta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYp2svquHHo-",
    "outputId": "f12234a6-0344-4bb5-9a19-8e067a10f312"
   },
   "outputs": [],
   "source": [
    "# Print the head of the DataFrame df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhqFNSZXHHo-",
    "outputId": "026534ee-5746-4787-bc5c-a5499eeef0a5"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfyc5zipHHo_",
    "outputId": "bc30de1c-c4e3-45a1-a192-907591316f8f"
   },
   "outputs": [],
   "source": [
    "# Plot histogram of one column of the DataFrame\n",
    "pd.DataFrame.hist(df[['disa10']])\n",
    "plt.xlabel('Extent of disease')\n",
    "plt.ylabel('Number of countries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfgmL_gWHHo_"
   },
   "source": [
    "### Importing HDF5 (Hierarachical Data Format Version 5) files\n",
    "\n",
    "It is used for storing large quantities of numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8F8htsqHHo_"
   },
   "outputs": [],
   "source": [
    "import h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlMHWcruHHo_",
    "outputId": "08fc3968-5270-4411-c8ae-0640638b787a"
   },
   "outputs": [],
   "source": [
    "# Assign filename: file\n",
    "file = 'L-L1_LOSC_4_V1-1126259446-32.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file,'r')\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "print(type(data))\n",
    "\n",
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmknZOztHHpA",
    "outputId": "2a737437-dcd1-4e0a-b11d-ef78b3329037"
   },
   "outputs": [],
   "source": [
    "# Get the HDF5 group: group\n",
    "group=data['strain']\n",
    "\n",
    "# Check out keys of group\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Set variable equal to time series data: strain\n",
    "strain=data['strain']['Strain'].value\n",
    "\n",
    "# Set number of time points to sample: num_samples\n",
    "\n",
    "num_samples=10000\n",
    "# Set time vector\n",
    "time = np.arange(0, 1, 1/num_samples)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(time, strain[:num_samples])\n",
    "plt.xlabel('GPS Time (s)')\n",
    "plt.ylabel('strain')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4otkTTYHHpA"
   },
   "source": [
    "### Importing MATLAB (Matrix Laboratory) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yp8BBVMcHHpA",
    "outputId": "bcc4e6f7-ed66-4871-947a-7b33a0da2ffc"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat=scipy.io.loadmat('ja_data2.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOPE-cdWHHpB",
    "outputId": "e2f84bf2-50a2-4f95-954e-b80b2dfe7dc8"
   },
   "outputs": [],
   "source": [
    "# Print the keys of the MATLAB dictionary\n",
    "print(mat.keys())\n",
    "\n",
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print(type(mat['CYratioCyt']))\n",
    "\n",
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "print(mat['CYratioCyt'].shape)\n",
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "fig = plt.figure()\n",
    "plt.plot(data)\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('normalized fluorescence (measure of expression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7olNOMZHHpB"
   },
   "source": [
    "### Downloading  flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fq3NysDRHHpB",
    "outputId": "095b77f1-9518-4c60-bb46-99af336fff5e"
   },
   "outputs": [],
   "source": [
    "# This block of code will download the wine data from the url and store it on the local computer\n",
    "\n",
    "from urllib.request import urlretrieve #importing the urlretrieve package\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "urlretrieve(url,'winequality-white.csv')# downloading and saving files on the local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veDBBvXvHHpB",
    "outputId": "5523cd71-2764-4060-f43e-68dba35aea90"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-white.csv',sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaacpNu9HHpB"
   },
   "source": [
    "### Downloading html data from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0arqRS4mHHpC"
   },
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.wikipedia.org/'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVhb47ReHHpC",
    "outputId": "58fbe0a3-bd6c-4d4d-cfff-f3667a6e8073"
   },
   "outputs": [],
   "source": [
    "print(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hcvLQ-eHHpC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsZ1tBy8HHpC",
    "outputId": "b738c2df-0aed-4345-ca31-6b83338736a2"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_doc)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndAUewpdHHpC"
   },
   "source": [
    "After downloading the html data,you can now scrape the needed information with BeautifulSoup or any other page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2N-8HVHHpC"
   },
   "source": [
    "### Loading a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEJ6ecf9HHpD"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#with open(file_name, 'r') as json_file:\n",
    "    #json_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJwmBucDHHpD",
    "outputId": "eb3bf103-2e6d-438d-e260-f4d020011205"
   },
   "outputs": [],
   "source": [
    "# Import requests package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=the+social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Print the text of the response\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNg4OO9vHHpD",
    "outputId": "b7202a60-8c6d-402d-8e46-bd0b89a845a0"
   },
   "outputs": [],
   "source": [
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eun8JXGtHHpD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOBPaac6HHpD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3xd5bLsHHpD"
   },
   "source": [
    "## Connecting to Relational Database with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYD3iMz1HHpE"
   },
   "source": [
    "Steps:\n",
    "1. import the necessary packages\n",
    "2. Create a database engine\n",
    "3. Connect to the database using the engine\n",
    "4. Query the database \n",
    "5. Save the query results to a DataFrame\n",
    "6. Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yMgShvzHHpE"
   },
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-G6_8_UHHpE",
    "outputId": "76b7633a-d3c1-47c6-aa24-8e4c7e22616b"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "#Check the names of tables in the Database\n",
    "table_names = engine.table_names()\n",
    "print(table_names)\n",
    "\n",
    "# Open engine connection: con\n",
    "con = engine.connect()\n",
    "\n",
    "# Perform query: rs\n",
    "rs = con.execute(\"SELECT * FROM Album\")\n",
    "\n",
    "# Save results of the query to DataFrame: df\n",
    "df = pd.DataFrame(rs)\n",
    "\n",
    "con.close() # Alaways remember to close your connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArKd-29oHHpE",
    "outputId": "1b561e47-3151-4237-fc44-6f53921028b8"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtQP46h_HHpE",
    "outputId": "64e69ec7-a6ac-43f1-f231-51a91fe13cee"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIxkvRfKHHpF"
   },
   "source": [
    "## Using context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifvRQuH-HHpF"
   },
   "outputs": [],
   "source": [
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "\n",
    "# Open engine in context manager\n",
    "# Perform query and save results to DataFrame: df\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT * FROM Employee WHERE EmployeeId >= 6\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6Iv1hFZHHpF"
   },
   "source": [
    "**Use context managers** so that you do not have to worry about closing connections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64L391C3HHpF"
   },
   "source": [
    "###  Querying Database directly from pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRLHNGb8HHpF"
   },
   "outputs": [],
   "source": [
    "# Create engine: engine\n",
    "engine = create_engine('sqlite:///Chinook.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPESKwnIHHpF"
   },
   "outputs": [],
   "source": [
    "# Execute query and store records in DataFrame: df\n",
    "df = pd.read_sql_query(\"SELECT * FROM Album\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgbyN0GGHHpF",
    "outputId": "04a291c2-e3aa-490d-da55-8479675be17b"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0HaH8ZuHHpG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data importation with python.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
